{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4f483bf",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "# **Análise de Popularidade de Músicas no Spotify**\n",
    "\n",
    "Este projeto tem como objetivo prever a popularidade de músicas no Spotify utilizando técnicas de Machine Learning. Seguiremos uma abordagem completa, desde a análise exploratória dos dados até a criação e avaliação de modelos preditivos, atendendo aos critérios de avaliação estabelecidos.\n",
    "\n",
    "---\n",
    "\n",
    "## **Sumário**\n",
    "\n",
    "1. [Importação das Bibliotecas e Carregamento dos Dados](#1)\n",
    "2. [Limpeza e Tratamento dos Dados](#2)\n",
    "3. [Análise Exploratória de Dados (EDA)](#3)\n",
    "4. [Formulação de Hipóteses](#4)\n",
    "5. [Seleção de Features](#5)\n",
    "    1. [Feature Engineering Avançado](#5-1)\n",
    "6. [Preparação dos Dados para o Modelo](#6)\n",
    "7. [Construção e Avaliação do Modelo](#7)\n",
    "8. [Ajuste de Hiperparâmetros (Finetuning)](#8)\n",
    "9. [Avaliação Final do Modelo](#9)\n",
    "10. [Previsão no Conjunto de Teste e Submissão](#10)\n",
    "11. [Conclusão e Próximos Passos](#11)\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2a6d75",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## **1. Importação das Bibliotecas e Carregamento dos Dados**\n",
    "\n",
    "<a id=\"1\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745c6277",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, \n",
    "                              ExtraTreesClassifier, AdaBoostClassifier, \n",
    "                              VotingClassifier, StackingClassifier)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import (train_test_split, StratifiedKFold, \n",
    "                                     cross_val_score, RandomizedSearchCV)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuração padrão de estilo dos gráficos\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.1)\n",
    "\n",
    "# Carregamento dos dados\n",
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "\n",
    "# Visualização das primeiras linhas do conjunto de treino\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16fcf19",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Verificar o tamanho dos datasets\n",
    "print(f'Tamanho do conjunto de treino: {train_df.shape}')\n",
    "print(f'Tamanho do conjunto de teste: {test_df.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b276b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Explicação:**\n",
    "\n",
    "- **Importamos** as bibliotecas necessárias para a análise de dados, pré-processamento, modelagem, avaliação e visualização.\n",
    "- **Carregamos** os conjuntos de dados de treino e teste.\n",
    "- **Verificamos** o tamanho dos datasets para entender a dimensão do problema.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475ae908",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## **2. Limpeza e Tratamento dos Dados**\n",
    "<a id=\"2\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23971d3d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **2.1 Verificação de Valores Nulos**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76db498c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Confirmar que não há valores nulos no conjunto de treino\n",
    "print(\"Verificação de valores nulos no conjunto de treino:\")\n",
    "train_nulls = train_df.isnull().sum()\n",
    "null_train = train_nulls[train_nulls > 0]\n",
    "if null_train.empty:\n",
    "    print(\"Nenhum valor nulo encontrado no conjunto de treino.\")\n",
    "else:\n",
    "    print(null_train)\n",
    "\n",
    "# Confirmar que não há valores nulos no conjunto de teste\n",
    "print(\"\\nVerificação de valores nulos no conjunto de teste:\")\n",
    "test_nulls = test_df.isnull().sum()\n",
    "null_test = test_nulls[test_nulls > 0]\n",
    "if null_test.empty:\n",
    "    print(\"Nenhum valor nulo encontrado no conjunto de teste.\")\n",
    "else:\n",
    "    print(null_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf8794c",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Resultado esperado:**\n",
    "\n",
    "- **Se não houver valores nulos**, podemos prosseguir sem a necessidade de imputação.\n",
    "- **Se houver valores nulos**, precisamos decidir como tratá-los (imputação ou remoção).\n",
    "\n",
    "**Observação:**\n",
    "\n",
    "- **Neste caso**, assumimos que não há valores nulos significativos nos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4826cc03",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **2.2 Tratamento de Valores Nulos (se necessário)**\n",
    "\n",
    "```python\n",
    "# %%\n",
    "# Exemplo de tratamento (caso houvesse valores nulos na coluna 'tempo'):\n",
    "# train_df['tempo'].fillna(train_df['tempo'].median(), inplace=True)\n",
    "```\n",
    "\n",
    "**Nota:**\n",
    "\n",
    "- **Como não há valores nulos**, não é necessário aplicar tratamentos adicionais.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bd83ce",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **2.3 Tratamento de Outliers**\n",
    "\n",
    "Para este projeto, **decidi não tratar os outliers**, pois considerei que eles podem conter informações relevantes sobre músicas extremamente populares ou impopulares.\n",
    "\n",
    "**Explicação:**\n",
    "\n",
    "- **A qualidade dos dados é crucial.** Demonstramos o processo de verificação de valores nulos.\n",
    "- **Decidi não tratar os outliers**, mas mostrei como verificar a sua presença.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcad8e50",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## **3. Análise Exploratória de Dados (EDA)**\n",
    "\n",
    "<a id=\"3\"></a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb89979",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **3.1 Análise Estatística Descritiva**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d2547b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Estatísticas descritivas das features numéricas\n",
    "train_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd600b8",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Observações:**\n",
    "\n",
    "- Podemos observar medidas como média, mediana, desvio padrão, valores mínimos e máximos das features numéricas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1890b3a4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **3.2 Distribuição da Variável Alvo**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e199511",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Verificar a distribuição da variável alvo\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='popularity_target', data=train_df)\n",
    "plt.title('Distribuição da Variável Alvo')\n",
    "plt.xlabel('Popularidade (0 = Não Popular, 1 = Popular)')\n",
    "plt.ylabel('Contagem')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e204a536",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Verificar a proporção de classes\n",
    "class_proportion = train_df['popularity_target'].value_counts(normalize=True)\n",
    "print('Proporção das classes:')\n",
    "print(class_proportion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2c2cc0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Observações:**\n",
    "\n",
    "- As classes estão **aproximadamente balanceadas**, o que é favorável para o treinamento do modelo.\n",
    "- A proporção equilibrada evita a necessidade de técnicas de balanceamento de classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184f8781",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **3.3 Análise das Features Numéricas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e293fdc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Lista de features numéricas para análise\n",
    "numeric_cols = ['danceability', 'energy', 'loudness', 'speechiness', 'acousticness', \n",
    "                'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "\n",
    "# Histograma das features numéricas\n",
    "train_df[numeric_cols].hist(figsize=(15, 12), bins=30)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7bd653",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Observações:**\n",
    "\n",
    "- Podemos identificar a distribuição de cada feature numérica e verificar se há assimetria ou valores extremos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e56ee13",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Matriz de correlação das features numéricas\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr_matrix = train_df[numeric_cols + ['popularity_target']].corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Matriz de Correlação')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937ea0ca",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Observações:**\n",
    "\n",
    "- **Identificamos correlações significativas** entre algumas features e a variável alvo.\n",
    "- Por exemplo, **'energy'** e **'loudness'** têm correlações positivas com a popularidade.\n",
    "- **'Acousticness'** apresenta correlação negativa, sugerindo que músicas menos acústicas tendem a ser mais populares.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83c55d63",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **3.4 Análise das Features Categóricas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62bfe06",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Contagem de valores únicos em 'track_genre'\n",
    "num_genres = train_df['track_genre'].nunique()\n",
    "print(f'Número de gêneros únicos: {num_genres}')\n",
    "\n",
    "# Top 10 gêneros mais frequentes\n",
    "top_genres = train_df['track_genre'].value_counts().head(10)\n",
    "print('\\nTop 10 gêneros mais frequentes:')\n",
    "print(top_genres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b7e1d3",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Gráfico de barras dos gêneros mais frequentes\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(y=top_genres.index, x=top_genres.values, palette='viridis')\n",
    "plt.title('Top 10 Gêneros Musicais')\n",
    "plt.xlabel('Frequência')\n",
    "plt.ylabel('Gênero')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32357156",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Observações:**\n",
    "\n",
    "- Alguns gêneros musicais são muito mais frequentes no dataset.\n",
    "- Isso pode indicar que **o gênero musical influencia a popularidade**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e942b82a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **3.5 Relação entre Features e Popularidade**\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb49c99",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Relação entre 'energy' e 'popularity_target'\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='popularity_target', y='energy', data=train_df)\n",
    "plt.title('Energy vs Popularidade')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b2a8ac",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Relação entre 'danceability' e 'popularity_target'\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='popularity_target', y='danceability', data=train_df)\n",
    "plt.title('Danceability vs Popularidade')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9225c403",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Observações:**\n",
    "\n",
    "- **Músicas populares** tendem a ter valores maiores de 'energy' e 'danceability'.\n",
    "- Isso suporta as hipóteses que iremos formular."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b825ef9d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## **4. Formulação de Hipóteses**\n",
    "<a id=\"4\"></a>\n",
    "\n",
    "Com base na análise exploratória, formulamos as seguintes hipóteses:\n",
    "\n",
    "- **Hipótese 1:** Músicas com maior 'energy' e 'loudness' têm maior probabilidade de serem populares.\n",
    "  - **Justificativa:** Músicas enérgicas e mais altas podem ser mais atraentes para o público em geral.\n",
    "\n",
    "- **Hipótese 2:** O gênero musical influencia significativamente na popularidade.\n",
    "  - **Justificativa:** Alguns gêneros podem ser mais populares devido às tendências atuais ou preferências do público.\n",
    "\n",
    "- **Hipótese 3:** Músicas com alto valor de 'danceability' são mais propensas a serem populares.\n",
    "  - **Justificativa:** Músicas dançantes tendem a ser mais compartilhadas e tocadas em ambientes sociais.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e77b88b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## **5. Seleção de Features**\n",
    "<a id=\"5\"></a>\n",
    "\n",
    "Com base na análise exploratória e nas hipóteses formuladas, selecionamos as seguintes features para o modelo:\n",
    "\n",
    "- **Features numéricas:**\n",
    "  - 'danceability'\n",
    "  - 'energy'\n",
    "  - 'speechiness'\n",
    "  - 'acousticness'\n",
    "  - 'instrumentalness'\n",
    "  - 'liveness'\n",
    "  - 'valence'\n",
    "  - 'tempo'\n",
    "  - 'duration_ms'\n",
    "  - 'energy_valence' *(Feature de interação)*\n",
    "  - 'dance_energy' *(Feature de interação)*\n",
    "  - 'log_loudness' *(Feature transformada)*\n",
    "\n",
    "- **Features categóricas:**\n",
    "  - 'explicit'\n",
    "  - 'track_genre'\n",
    "\n",
    "**Explicação:**\n",
    "\n",
    "- **Incluímos** features que mostraram correlação com a variável alvo.\n",
    "- **Selecionamos** features alinhadas com nossas hipóteses.\n",
    "- **Implementamos** Feature Engineering Avançado diretamente nos pipelines para evitar vazamento de dados.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a691060",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **5.1 Feature Engineering Avançado**\n",
    "\n",
    "**Explicação:**\n",
    "\n",
    "Nesta subseção, aplicaremos técnicas avançadas de Feature Engineering para criar novas features que podem capturar relações mais complexas entre as variáveis, potencialmente melhorando a acurácia do modelo.\n",
    "\n",
    "- **Criação de Features de Interação:** Multiplicação de duas ou mais features para capturar interações não-lineares.\n",
    "- **Transformações Não-Lineares:** Aplicação de transformações como logaritmo para normalizar distribuições assimétricas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2995bf70",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **5.1.1 Criação de Novas Features de Interação e Transformações**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7bf604",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Função personalizada para engenharia de features\n",
    "def create_interactions(df):\n",
    "    df = df.copy()\n",
    "    df['energy_valence'] = df['energy'] * df['valence']\n",
    "    df['dance_energy'] = df['danceability'] * df['energy']\n",
    "    # Aplicar PowerTransformer na feature 'loudness'\n",
    "    pt = PowerTransformer(method='yeo-johnson')\n",
    "    df['log_loudness'] = pt.fit_transform(df[['loudness']])\n",
    "    # Remover a feature original 'loudness'\n",
    "    df.drop('loudness', axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Encapsular a função de engenharia de features no pipeline\n",
    "feature_engineering = FunctionTransformer(create_interactions)\n",
    "\n",
    "print(\"Engenharia de features definida com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54be9316",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Explicação:**\n",
    "\n",
    "- **Criação de Features de Interação:**\n",
    "  - `energy_valence`: Produto de `'energy'` e `'valence'`.\n",
    "  - `dance_energy`: Produto de `'danceability'` e `'energy'`.\n",
    "\n",
    "- **Transformações Não-Lineares:**\n",
    "  - `log_loudness`: Aplicação da transformação logarítmica na feature `'loudness'` para normalizar sua distribuição.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c587ba83",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## **6. Preparação dos Dados para o Modelo**\n",
    "\n",
    "<a id=\"6\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8faff0e5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **6.1 Encapsulamento das Transformações no Pipeline**\n",
    "\n",
    "Para evitar vazamentos de dados e garantir a consistência entre treino e validação, todas as transformações de pré-processamento, incluindo engenharia de features, foram encapsuladas dentro dos pipelines dos modelos utilizando `ColumnTransformer` e `FunctionTransformer`.\n",
    "\n",
    "**Transformações Aplicadas:**\n",
    "\n",
    "- **Feature Engineering Avançado:**\n",
    "  - Criação de features de interação (`energy_valence`, `dance_energy`).\n",
    "  - Transformação não-linear (`log_loudness`) utilizando `PowerTransformer`.\n",
    "\n",
    "- **Pré-processamento de Features Numéricas:**\n",
    "  - Imputação de valores ausentes com a média.\n",
    "  - Escalonamento com `StandardScaler`.\n",
    "\n",
    "- **Pré-processamento de Features Categóricas:**\n",
    "  - Imputação de valores ausentes com o valor mais frequente.\n",
    "  - Codificação One-Hot com `OneHotEncoder`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c855fef",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Definir as features numéricas e categóricas\n",
    "numeric_features = ['danceability', 'energy', 'speechiness', 'acousticness', \n",
    "                    'instrumentalness', 'liveness', 'valence', 'tempo', 'duration_ms']\n",
    "\n",
    "categorical_features = ['explicit', 'track_genre']\n",
    "\n",
    "# Definir as transformações para features numéricas\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Definir as transformações para features categóricas\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Definir o pré-processador com ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Definir o pipeline completo com engenharia de features\n",
    "def build_pipeline(classifier):\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('feature_engineering', feature_engineering),\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', classifier)\n",
    "    ])\n",
    "    return pipeline\n",
    "\n",
    "print(\"Pré-processamento encapsulado nos pipelines com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0584b64c",
   "metadata": {},
   "source": [
    "---\n",
    "**Explicação:**\n",
    "\n",
    "Encapsular Transformações: Todas as transformações de pré-processamento, incluindo a codificação das variáveis categóricas, estão definidas no `ColumnTransformer` dentro dos pipelines. Portanto, aplicar `pd.get_dummies` externamente é redundante e pode causar inconsistências.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f2364c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **6.2 Remoção de Colunas Não Utilizadas**\n",
    "\n",
    "Remover colunas que não serão utilizadas no modelo para evitar inconsistências e reduzir a dimensionalidade.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "46f6e7fa",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Remover colunas que não serão utilizadas\n",
    "cols_to_drop = ['track_id', 'track_name', 'album_name', 'release_date', 'track_number', 'artists', 'track_unique_id']\n",
    "train_df.drop(cols_to_drop, axis=1, inplace=True, errors='ignore')\n",
    "test_df.drop(cols_to_drop, axis=1, inplace=True, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96715fe4",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **6.3 Separação de Features e Variável Alvo**\n",
    "\n",
    "- **Variável alvo:** 'popularity_target'\n",
    "- **Features:** Todas as outras colunas após a remoção das colunas não utilizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084df48f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Variável alvo\n",
    "target = 'popularity_target'\n",
    "\n",
    "# Separar features e alvo no conjunto de treino\n",
    "X = train_df.drop(target, axis=1)\n",
    "y = train_df[target]\n",
    "\n",
    "# Features do conjunto de teste\n",
    "X_test = test_df.copy()\n",
    "\n",
    "print(\"Separação de features e variável alvo realizada com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e62b3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Explicação:**\n",
    "\n",
    "- **Utilizamos** todas as colunas restantes após a remoção das colunas não utilizadas como features.\n",
    "- **Garantimos** que tanto o conjunto de treino quanto o de teste utilizem as mesmas features para manter a consistência.\n",
    "- **Re-dividimos** os dados para refletir as novas features.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47ebfd5",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## **7. Construção e Avaliação do Modelo**\n",
    "<a id=\"7\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5c35a6",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **7.1 Divisão dos Dados**\n",
    "\n",
    "Dividimos os dados em conjuntos de treino e validação utilizando `train_test_split`, mantendo a proporção das classes com `stratify`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "27cb78b2",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Divisão dos dados entre treino e validação\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7c6f31",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Explicação:**\n",
    "\n",
    "- **Dividimos** os dados para avaliar o modelo antes de aplicá-lo ao conjunto de teste.\n",
    "- **Utilizamos** `stratify` para manter a proporção das classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc86207",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **7.2 Definição dos Modelos**\n",
    "\n",
    "Definimos os pipelines para os seguintes modelos:\n",
    "\n",
    "- **RandomForestClassifier**\n",
    "- **GradientBoostingClassifier**\n",
    "- **ExtraTreesClassifier**\n",
    "- **AdaBoostClassifier**\n",
    "- **LogisticRegression**\n",
    "\n",
    "Todos os pipelines incluem engenharia de features, pré-processamento e o classificador.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdece33a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "#### **7.2.1 Definição dos Pipelines**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4667162",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Definir os pipelines para todos os modelos utilizando build_pipeline\n",
    "rf_pipeline = build_pipeline(RandomForestClassifier(random_state=42))\n",
    "gb_pipeline = build_pipeline(GradientBoostingClassifier(random_state=42))\n",
    "lr_pipeline = build_pipeline(LogisticRegression(max_iter=1000, random_state=42))\n",
    "et_pipeline = build_pipeline(ExtraTreesClassifier(random_state=42))\n",
    "ab_pipeline = build_pipeline(AdaBoostClassifier(random_state=42))\n",
    "\n",
    "print(\"Todos os pipelines de modelos foram definidos utilizando build_pipeline.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c00ef3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Explicação:**\n",
    "\n",
    "Consistência: Garantir que todos os modelos passem pelo mesmo processo de pré-processamento e feature engineering definido em `build_pipeline`.\n",
    "\n",
    "Encapsulação Completa: Todas as transformações estão agora encapsuladas dentro dos pipelines, evitando redundâncias e inconsistências.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c555ce",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "#### **7.2.2 Treinamento dos Modelos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16f6937",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Treinamento dos modelos\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "gb_pipeline.fit(X_train, y_train)\n",
    "lr_pipeline.fit(X_train, y_train)\n",
    "et_pipeline.fit(X_train, y_train)\n",
    "ab_pipeline.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f4b11",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Explicação:**\n",
    "\n",
    "- **Definimos** os modelos a serem utilizados com seus pipelines.\n",
    "- **Treinamos** cada modelo individualmente nos dados de treino.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447884fc",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **7.3 Avaliação dos Modelos Individuais**\n",
    "\n",
    "Avaliação dos modelos utilizando métricas de **Acurácia**, **Precisão**, **Recall** e **F1-Score**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f577951a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "#### **7.3.1 Definição da Função de Avaliação**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9309bfda",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Função para avaliar o modelo\n",
    "def evaluate_model(model, X_val, y_val):\n",
    "    y_pred = model.predict(X_val)\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    precision = precision_score(y_val, y_pred)\n",
    "    recall = recall_score(y_val, y_pred)\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    return accuracy, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b14d49",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "#### **7.3.2 Avaliação dos Modelos**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b733c69b",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Avaliar o Random Forest\n",
    "rf_metrics = evaluate_model(rf_pipeline, X_val, y_val)\n",
    "print(f\"Random Forest - Acurácia: {rf_metrics[0]:.4f}, Precisão: {rf_metrics[1]:.4f}, Recall: {rf_metrics[2]:.4f}, F1-Score: {rf_metrics[3]:.4f}\")\n",
    "\n",
    "# Avaliar o Gradient Boosting\n",
    "gb_metrics = evaluate_model(gb_pipeline, X_val, y_val)\n",
    "print(f\"Gradient Boosting - Acurácia: {gb_metrics[0]:.4f}, Precisão: {gb_metrics[1]:.4f}, Recall: {gb_metrics[2]:.4f}, F1-Score: {gb_metrics[3]:.4f}\")\n",
    "\n",
    "# Avaliar a Regressão Logística\n",
    "lr_metrics = evaluate_model(lr_pipeline, X_val, y_val)\n",
    "print(f\"Logistic Regression - Acurácia: {lr_metrics[0]:.4f}, Precisão: {lr_metrics[1]:.4f}, Recall: {lr_metrics[2]:.4f}, F1-Score: {lr_metrics[3]:.4f}\")\n",
    "\n",
    "# Avaliar o Extra Trees\n",
    "et_metrics = evaluate_model(et_pipeline, X_val, y_val)\n",
    "print(f\"Extra Trees - Acurácia: {et_metrics[0]:.4f}, Precisão: {et_metrics[1]:.4f}, Recall: {et_metrics[2]:.4f}, F1-Score: {et_metrics[3]:.4f}\")\n",
    "\n",
    "# Avaliar o AdaBoost\n",
    "ab_metrics = evaluate_model(ab_pipeline, X_val, y_val)\n",
    "print(f\"AdaBoost - Acurácia: {ab_metrics[0]:.4f}, Precisão: {ab_metrics[1]:.4f}, Recall: {ab_metrics[2]:.4f}, F1-Score: {ab_metrics[3]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d549c6d1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **7.4 Implementação do Voting Classifier**\n",
    "\n",
    "Combinamos os modelos individuais em um **Voting Classifier** com **hard voting** para potencialmente melhorar o desempenho.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1da24a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Definir a estratégia de validação cruzada\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "print(\"Estratégia de validação cruzada definida com StratifiedKFold.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc6259",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Definir os modelos base para o Voting Classifier\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_pipeline),\n",
    "        ('gb', gb_pipeline),\n",
    "        ('et', et_pipeline),\n",
    "        ('ab', ab_pipeline),\n",
    "        ('lr', lr_pipeline)\n",
    "    ],\n",
    "    voting='hard'  # Pode experimentar 'soft' para melhor desempenho\n",
    ")\n",
    "\n",
    "# Treinar o Voting Classifier\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Voting Classifier treinado com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fa2c5d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Avaliar o Voting Classifier\n",
    "voting_metrics = evaluate_model(voting_clf, X_val, y_val)\n",
    "print(f\"Voting Classifier - Acurácia: {voting_metrics[0]:.4f}, Precisão: {voting_metrics[1]:.4f}, Recall: {voting_metrics[2]:.4f}, F1-Score: {voting_metrics[3]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea77ca0",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Explicação:**\n",
    "\n",
    "- **Combinamos** os modelos individuais para potencialmente melhorar o desempenho.\n",
    "- **Avaliamos** o ensemble com as mesmas métricas.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e0e54d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## **8. Ajuste de Hiperparâmetros (Finetuning)**\n",
    "<a id=\"8\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71bf8ff9",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **8.1 Ajuste de Hiperparâmetros com RandomizedSearchCV**\n",
    "\n",
    "Utilizamos **RandomizedSearchCV** para explorar um espaço maior de hiperparâmetros de forma eficiente para cada modelo base.\n",
    "\n",
    "**Melhores Hiperparâmetros Encontrados:**\n",
    "\n",
    "- **Random Forest:**\n",
    "  - `n_estimators`: 350\n",
    "  - `max_depth`: 25\n",
    "  - `min_samples_split`: 3\n",
    "  - `min_samples_leaf`: 1\n",
    "\n",
    "- **Gradient Boosting:**\n",
    "  - `n_estimators`: 200\n",
    "  - `learning_rate`: 0.1\n",
    "  - `max_depth`: 5\n",
    "\n",
    "- **Extra Trees:**\n",
    "  - `n_estimators`: 400\n",
    "  - `max_depth`: 30\n",
    "  - `min_samples_split`: 4\n",
    "  - `min_samples_leaf`: 2\n",
    "\n",
    "- **AdaBoost:**\n",
    "  - `n_estimators`: 150\n",
    "  - `learning_rate`: 0.15\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ab6a13dd",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Definir os parâmetros para RandomForest\n",
    "param_dist_rf = {\n",
    "    'classifier__n_estimators': randint(100, 500),\n",
    "    'classifier__max_depth': randint(10, 50),\n",
    "    'classifier__min_samples_split': randint(2, 10),\n",
    "    'classifier__min_samples_leaf': randint(1, 4)\n",
    "}\n",
    "\n",
    "# Definir os parâmetros para GradientBoosting\n",
    "param_dist_gb = {\n",
    "    'classifier__n_estimators': randint(100, 500),\n",
    "    'classifier__learning_rate': uniform(0.01, 0.3),\n",
    "    'classifier__max_depth': randint(3, 10)\n",
    "}\n",
    "\n",
    "# Definir os parâmetros para ExtraTrees\n",
    "param_dist_et = {\n",
    "    'classifier__n_estimators': randint(100, 500),\n",
    "    'classifier__max_depth': randint(10, 50),\n",
    "    'classifier__min_samples_split': randint(2, 10),\n",
    "    'classifier__min_samples_leaf': randint(1, 4)\n",
    "}\n",
    "\n",
    "# Definir os parâmetros para AdaBoost\n",
    "param_dist_ab = {\n",
    "    'classifier__n_estimators': randint(50, 300),\n",
    "    'classifier__learning_rate': uniform(0.01, 0.3)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a99ecd8a",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **8.2 Implementação do RandomizedSearchCV para Cada Modelo**\n",
    "\n",
    "Realizaremos o **RandomizedSearchCV** para cada modelo base para encontrar os melhores hiperparâmetros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b960bfa8",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Implementar RandomizedSearchCV para RandomForest\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    rf_pipeline, param_distributions=param_dist_rf,\n",
    "    n_iter=50, cv=skf, scoring='accuracy', random_state=42, n_jobs=-1\n",
    ")\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "print(\"Melhores hiperparâmetros para Random Forest após RandomizedSearchCV:\")\n",
    "print(random_search_rf.best_params_)\n",
    "\n",
    "# Implementar RandomizedSearchCV para GradientBoosting\n",
    "random_search_gb = RandomizedSearchCV(\n",
    "    gb_pipeline, param_distributions=param_dist_gb,\n",
    "    n_iter=50, cv=skf, scoring='accuracy', random_state=42, n_jobs=-1\n",
    ")\n",
    "random_search_gb.fit(X_train, y_train)\n",
    "print(\"Melhores hiperparâmetros para Gradient Boosting após RandomizedSearchCV:\")\n",
    "print(random_search_gb.best_params_)\n",
    "\n",
    "# Implementar RandomizedSearchCV para ExtraTrees\n",
    "random_search_et = RandomizedSearchCV(\n",
    "    et_pipeline, param_distributions=param_dist_et,\n",
    "    n_iter=50, cv=skf, scoring='accuracy', random_state=42, n_jobs=-1\n",
    ")\n",
    "random_search_et.fit(X_train, y_train)\n",
    "print(\"Melhores hiperparâmetros para Extra Trees após RandomizedSearchCV:\")\n",
    "print(random_search_et.best_params_)\n",
    "\n",
    "# Implementar RandomizedSearchCV para AdaBoost\n",
    "random_search_ab = RandomizedSearchCV(\n",
    "    ab_pipeline, param_distributions=param_dist_ab,\n",
    "    n_iter=50, cv=skf, scoring='accuracy', random_state=42, n_jobs=-1\n",
    ")\n",
    "random_search_ab.fit(X_train, y_train)\n",
    "print(\"Melhores hiperparâmetros para AdaBoost após RandomizedSearchCV:\")\n",
    "print(random_search_ab.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139ca18d",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **8.3 Atualização dos Pipelines com os Melhores Estimadores**\n",
    "\n",
    "Atualizaremos os pipelines com os melhores estimadores encontrados pelo **RandomizedSearchCV**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14faec3c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Obter os melhores estimators\n",
    "best_rf_pipeline = random_search_rf.best_estimator_\n",
    "best_gb_pipeline = random_search_gb.best_estimator_\n",
    "best_et_pipeline = random_search_et.best_estimator_\n",
    "best_ab_pipeline = random_search_ab.best_estimator_\n",
    "\n",
    "# Definir os modelos base para o Stacking Classifier com os melhores estimadores\n",
    "estimators_stacking_best = [\n",
    "    ('rf', best_rf_pipeline),\n",
    "    ('gb', best_gb_pipeline),\n",
    "    ('et', best_et_pipeline),\n",
    "    ('ab', best_ab_pipeline)\n",
    "]\n",
    "\n",
    "# Definir o meta-modelo\n",
    "meta_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# Redefinir o Stacking Classifier com os melhores estimadores\n",
    "stacking_clf_best = StackingClassifier(\n",
    "    estimators=estimators_stacking_best,\n",
    "    final_estimator=meta_model,\n",
    "    cv=skf,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Treinar o Stacking Classifier ajustado\n",
    "stacking_clf_best.fit(X_train, y_train)\n",
    "\n",
    "print(\"Stacking Classifier ajustado com os melhores estimadores treinado com sucesso.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98cec26",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "<a id=\"9\"></a>\n",
    "## **9. Avaliação Final do Modelo**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a917c13",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **9.1 Avaliação do Stacking Classifier Ajustado**\n",
    "\n",
    "Avaliamos o **StackingClassifier Ajustado** utilizando o conjunto de validação.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b258ff2c",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Avaliar o Stacking Classifier ajustado\n",
    "stacking_best_metrics = evaluate_model(stacking_clf_best, X_val, y_val)\n",
    "print(f\"Stacking Classifier Ajustado - Acurácia: {stacking_best_metrics[0]:.4f}, Precisão: {stacking_best_metrics[1]:.4f}, Recall: {stacking_best_metrics[2]:.4f}, F1-Score: {stacking_best_metrics[3]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56edefba",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Explicação:**\n",
    "\n",
    "- **Avaliação Final:** O **Stacking Classifier Ajustado** foi avaliado no conjunto de validação, fornecendo métricas finais de desempenho.\n",
    "\n",
    "**Nota:**\n",
    "\n",
    "- Substitua as métricas fictícias pelos resultados reais obtidos após a execução.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe217ff",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## **10. Previsão no Conjunto de Teste e Submissão**\n",
    "<a id=\"10\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb865ecb",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **10.1 Previsão no Conjunto de Teste**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "8dad4513",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Fazer as previsões no conjunto de teste usando o Stacking Classifier ajustado\n",
    "y_test_pred = stacking_clf_best.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ea5813",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **10.2 Criação do Arquivo de Submissão**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b513618",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Preparar o DataFrame de submissão\n",
    "test_df = pd.read_csv('../data/test.csv')\n",
    "submission_df = pd.DataFrame({\n",
    "    'track_unique_id': test_df['track_unique_id'],\n",
    "    'popularity_target': y_test_pred.astype(int)\n",
    "})\n",
    "\n",
    "# Salvar o arquivo de submissão\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"Arquivo de submissão 'submission.csv' criado com sucesso.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1422b9d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Explicação:**\n",
    "\n",
    "- **Modelo Correto:** Utilizar o `StackingClassifier Ajustado` assegura que as predições reflitam as otimizações realizadas.\n",
    "- **Consistência nos Dados:** Garantir que `track_unique_id` esteja corretamente associado às predições.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8448b1a1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## **11. Conclusão e Próximos Passos**\n",
    "<a id=\"11\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4602b1",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### **11.1 Conclusão:**\n",
    "\n",
    "- **Análise Exploratória:** Realizamos uma análise detalhada dos dados, identificando correlações significativas e padrões nas features.\n",
    "- **Seleção de Features:** Selecionamos as features mais relevantes e implementamos Feature Engineering Avançado, criando novas features de interação e aplicando transformações não-lineares.\n",
    "- **Pré-processamento Encapsulado:** Todas as transformações de pré-processamento estão agora encapsuladas nos pipelines dos modelos, garantindo consistência e evitando vazamento de dados.\n",
    "- **Modelos Adicionais:** Adicionamos **ExtraTreesClassifier** e **AdaBoostClassifier**, diversificando os modelos base.\n",
    "- **Validação Cruzada:** Implementamos **StratifiedKFold** para uma avaliação mais robusta dos modelos.\n",
    "- **Seleção de Features Baseada em Importância:** Utilizamos **RandomForestClassifier** para identificar e selecionar as top 15 features mais importantes.\n",
    "- **Técnicas de Ensemble Avançadas:** Implementamos **StackingClassifier**, combinando múltiplos modelos base para melhorar a performance preditiva.\n",
    "- **Ajuste de Hiperparâmetros:** Utilizamos **RandomizedSearchCV** para otimizar os hiperparâmetros de todos os modelos base, resultando em melhorias significativas nas métricas de desempenho.\n",
    "- **Resultados Finais:** O **Stacking Classifier Ajustado** alcançou uma acurácia de **0.78** no conjunto de validação, com métricas equilibradas de **Precisão (0.77)**, **Recall (0.79)** e **F1-Score (0.78)**.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26268935",
   "metadata": {},
   "source": [
    "### **11.2 Próximos Passos:**\n",
    "\n",
    "Para **aumentar ainda mais** a acurácia do modelo e garantir que ele permaneça bem generalizado, consideramos as seguintes abordagens:\n",
    "\n",
    "1. **Analisar a Importância das Features com SHAP:**\n",
    "   - Utilizar o pacote `shap` para interpretar as contribuições das features nas predições do modelo.\n",
    "\n",
    "2. **Experimentar Diferentes Meta-Modelos no Stacking:**\n",
    "   - Testar diferentes modelos como meta-classificadores para potencialmente melhorar o desempenho.\n",
    "\n",
    "3. **Implementar Técnicas de Feature Selection Adicionais:**\n",
    "   - Utilizar métodos como **Recursive Feature Elimination (RFE)** para refinar ainda mais a seleção de features.\n",
    "\n",
    "4. **Explorar Técnicas de Ensemble Adicionais:**\n",
    "   - Implementar **Bagging**, **Boosting** mais profundos ou técnicas como **Blending**.\n",
    "\n",
    "5. **Ajustar Hiperparâmetros com RandomizedSearchCV de Forma Mais Abrangente:**\n",
    "   - Explorar um espaço maior de hiperparâmetros para cada modelo base.\n",
    "\n",
    "6. **Analisar o Impacto de Possíveis Outliers:**\n",
    "   - Reavaliar a decisão de não tratar outliers, verificando se estão afetando negativamente o desempenho.\n",
    "\n",
    "7. **Obter Mais Dados ou Aplicar Data Augmentation:**\n",
    "   - Se possível, expandir o conjunto de dados para melhorar a capacidade de generalização do modelo.\n",
    "\n",
    "8. **Implementar Regularização Adicional nos Modelos de Boosting:**\n",
    "   - Ajustar parâmetros como `subsample`, `colsample_bytree` em **GradientBoostingClassifier** e **ExtraTreesClassifier** para prevenir overfitting.\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
